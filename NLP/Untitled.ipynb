{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import operator\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "Stopwords = set(stopwords.words('english'))\n",
    "wordlemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    regex = r'[^a-zA-Z0-9\\s]'\n",
    "    text = re.sub(regex,'',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Women education is a catch all term which refers to the state of primary, \n",
    "secondary, tertiary and health education in girls and women. There are 65 Million girls \n",
    "out of school across the globe; majority of them are in the developing and underdeveloped \n",
    "countries. All the countries of the world, especially the developing and underdeveloped \n",
    "countries must take necessary steps to improve their condition of female education; \n",
    "as women can play a vital role in the nationâ€™s development.\n",
    "'''\n",
    "\n",
    "tokenized_sentence = sent_tokenize(text)\n",
    "text = remove_special_characters(str(text))\n",
    "text = re.sub(r'\\d+', '', text)\n",
    "tokenized_words_with_stopwords = word_tokenize(text)\n",
    "tokenized_words = [word for word in tokenized_words_with_stopwords if word not in Stopwords]\n",
    "tokenized_words = [word for word in tokenized_words if len(word) > 1]\n",
    "tokenized_words = [word.lower() for word in tokenized_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(words):\n",
    "    words = [word.lower() for word in words]\n",
    "    dict_freq = {}\n",
    "    words_unique = []\n",
    "    for word in words:\n",
    "        if word not in words_unique:\n",
    "            words_unique.append(word)\n",
    "    for word in words_unique:\n",
    "          dict_freq[word] = words.count(word)\n",
    "    return dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_importance(sentence,dict_freq,sentences):\n",
    "    sentence_score = 0\n",
    "    sentence = remove_special_characters(str(sentence))\n",
    "    sentence = re.sub(r'\\d+', '', sentence)\n",
    "    pos_tagged_sentence = []\n",
    "    no_of_sentences = len(sentences)\n",
    "    pos_tagged_sentence = pos_tagging(sentence)\n",
    "    for word in pos_tagged_sentence:\n",
    "        if word.lower() not in Stopwords and word not in Stopwords    and len(word)>1:\n",
    "            word = word.lower() \n",
    "            word = wordlemmatizer.lemmatize(word)\n",
    "            sentence_score = sentence_score + word_tfidf(dict_freq,word,sentences)\n",
    "    return sentence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(text):\n",
    "    pos_tag = nltk.pos_tag(text.split())\n",
    "    pos_tagged_noun_verb = []\n",
    "    for word,tag in pos_tag:\n",
    "        if tag == \"NN\" or tag == \"NNP\" or tag == \"NNS\" or tag == \"VB\" or tag == \"VBD\" or tag == \"VBG\" or tag == \"VBN\" or tag == \"VBP\" or tag == \"VBZ\":\n",
    "            pos_tagged_noun_verb.append(word)\n",
    "    return pos_tagged_noun_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tfidf(dict_freq,word,sentences):\n",
    "    word_tfidf = [] \n",
    "    tf = tf_score(word,sentences)\n",
    "    idf = idf_score(len(sentences),word,sentences)\n",
    "    tf_idf = tf_idf_score(tf,idf)\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_score(word,sentence):\n",
    "    freq_sum = 0\n",
    "    word_frequency_in_sentence = 0\n",
    "    len_sentence = len(sentence)\n",
    "    for word_in_sentence in sentence.split():\n",
    "        if word == word_in_sentence:\n",
    "            word_frequency_in_sentence = word_frequency_in_sentence + 1\n",
    "    tf =  word_frequency_in_sentence/ len_sentence\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_score(no_of_sentences,word,sentences):\n",
    "    no_of_sentence_containing_word = 0\n",
    "    for sentence in sentences:\n",
    "        sentence = remove_special_characters(str(sentence))\n",
    "        sentence = re.sub(r'\\d+', '', sentence)\n",
    "        sentence = sentence.split()\n",
    "        sentence = [word for word in sentence if word.lower() not in Stopwords and len(word)>1]\n",
    "        sentence = [word.lower() for word in sentence]\n",
    "        sentence = [wordlemmatizer.lemmatize(word) for word in sentence]\n",
    "        if word in sentence:\n",
    "            no_of_sentence_containing_word = no_of_sentence_containing_word + 1\n",
    "    idf = math.log10(no_of_sentences/no_of_sentence_containing_word)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_score(tf,idf):\n",
    "    return tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c62380e3ee15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msentenceimp\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msentence_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msentence_with_importance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentenceimp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msentence_with_importance\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_with_importance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-04a2167d6330>\u001b[0m in \u001b[0;36msentence_importance\u001b[1;34m(sentence, dict_freq, sentences)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0msentence_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword_tfidf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msentence_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-d18fa216772a>\u001b[0m in \u001b[0;36mword_tfidf\u001b[1;34m(dict_freq, word, sentences)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mword_tfidf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mword_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0midf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midf_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtf_idf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_idf_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-cccdeef09c34>\u001b[0m in \u001b[0;36mtf_score\u001b[1;34m(word, sentence)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mword_frequency_in_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlen_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mword_in_sentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mword_in_sentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mword_frequency_in_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_frequency_in_sentence\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for sent in tokenized_sentence:\n",
    "    sentenceimp =  sentence_importance(sent,freq(tokenized_words),tokenized_sentence)\n",
    "    sentence_with_importance[c] = sentenceimp\n",
    "    c = c+1\n",
    "    sentence_with_importance =  sorted(sentence_with_importance.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    cnt = 0\n",
    "    summary = []\n",
    "    sentence_no = []\n",
    "    for word_prob in sentence_with_importance:\n",
    "        if cnt < no_of_sentences:\n",
    "            sentence_no.append(word_prob[0])\n",
    "            cnt = cnt+1\n",
    "        else:\n",
    "            break\n",
    "sentence_no.sort()\n",
    "cnt = 1\n",
    "for sentence in tokenized_sentence:\n",
    "    if cnt in sentence_no:\n",
    "        summary.append(sentence)\n",
    "    cnt = cnt+1\n",
    "\n",
    "    summary = \" \".join(summary)\n",
    "print(\"\\n\")\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Women education is a catch all term which refers to the state of primary, \\nsecondary, tertiary and health education in girls and women.',\n",
       " 'There are 65 Million girls \\nout of school across the globe; majority of them are in the developing and underdeveloped \\ncountries.',\n",
       " 'All the countries of the world, especially the developing and underdeveloped \\ncountries must take necessary steps to improve their condition of female education; \\nas women can play a vital role in the nationâ€™s development.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
